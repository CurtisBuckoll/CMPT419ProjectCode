{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "726MBLLEN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBiMlfT9pTth",
        "colab_type": "code",
        "outputId": "5cca9320-9e0f-4431-e7e2-badcc00d633d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 3.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 85.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDgkyImhrfy2",
        "colab_type": "code",
        "outputId": "1af9ac99-634e-455d-9633-61baa1a41a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# SET UP\n",
        "\n",
        "# Data loader\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy\n",
        "import os\n",
        "import cv2 as cv\n",
        "from tensorflow import keras\n",
        "\n",
        "# Network\n",
        "#from keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "#from keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, UpSampling2D, Conv2DTranspose, Reshape, Dropout, concatenate, Concatenate, multiply, add, MaxPooling2D, Lambda, Activation, subtract, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "#from keras_contrib.layers.normalization import InstanceNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import imageio\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "#from data_load import Dataloader\n",
        "from scipy import misc\n",
        "#from glob import glob\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy\n",
        "import platform\n",
        "#import keras\n",
        "import os\n",
        "import random\n",
        "#import Network\n",
        "#import utls\n",
        "\n",
        "# Access Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaznQ1kyhfcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filep = '/content/drive/My Drive/726FinalProj/dataset/train_test/*.png'\n",
        "# ==================================================================\n",
        "# PARAMS\n",
        "ROOT_DIR = '/content/drive/My Drive/726FinalProj'\n",
        "DATA_FOLDER_HI = '/high' #'/high_small_size'\n",
        "DATA_FOLDER_LO = '/low'  #'/low_small_size'\n",
        "BATCH_SIZE = 8 # original: 16\n",
        "NUM_EPOCHS = 1  # original: 5\n",
        "STEPS_PER_EPOCH = 1  # num_samples // batch_size, in general, for our data should be 30.\n",
        "img_rows = 256\n",
        "img_cols = 256\n",
        "VAL_DIR = '/val_images2'\n",
        "\n",
        "BASE_LEARN_RATE    = 1*1e-03\n",
        "\n",
        "LOAD_FROM_WEIGHTS  = True\n",
        "MODEL_WEIGHTS_FILE = '12em.h5'\n",
        "RESUMED_LEARN_RATE = 0.0 #3.772367e-11 #1.5039908e-06 #7.5471934e-11\n",
        "# =================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Pl8fTZ1PPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Dataloader():\n",
        "    def __init__(self, dataset_name, crop_shape=(256, 256)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.crop_shape = crop_shape\n",
        "\n",
        "    def imread_color(self, path):\n",
        "        img = cv.imread(path, cv.IMREAD_COLOR | cv.IMREAD_ANYDEPTH) /255.\n",
        "        b, g, r = cv.split(img)\n",
        "        img_rgb = cv.merge([r, g, b])\n",
        "        return img_rgb\n",
        "\n",
        "    def imwrite(self, path, img):\n",
        "        r, g, b = cv.split(img)\n",
        "        img_rgb = cv.merge([b, g, r])\n",
        "        cv.imwrite(path, img_rgb)\n",
        "\n",
        "    def load_data(self, batch_size=16):\n",
        "        path = glob(ROOT_DIR + '/dataset/our485' + DATA_FOLDER_HI + '/*.png')\n",
        "        self.n_batches = int(len(path) / batch_size)\n",
        "        while 1:\n",
        "            random.shuffle(path)\n",
        "            for i in range(self.n_batches - 1):\n",
        "                batch_path = path[i * batch_size:(i + 1) * batch_size]\n",
        "                input_imgs = np.empty((batch_size, self.crop_shape[0], self.crop_shape[1], 6), dtype=\"float32\")\n",
        "                gt = np.empty((batch_size, self.crop_shape[0], self.crop_shape[1], 3), dtype=\"float32\")\n",
        "\n",
        "                number = 0\n",
        "                for img_B_path in batch_path:\n",
        "                    img_B = self.imread_color(img_B_path)\n",
        "\n",
        "                    path_split = os.path.split(img_B_path)\n",
        "                    path_prefix = os.path.split(path_split[0])\n",
        "                    path_A = path_prefix[0] + DATA_FOLDER_LO + '/' + path_split[1]\n",
        "\n",
        "                    # path_mid = os.path.split(img_B_path)\n",
        "                    # path_A_1 = path_mid[0] + '_' + self.dataset_name\n",
        "                    # path_A = os.path.join(path_A_1, path_mid[1])\n",
        "                    \n",
        "                    img_A = self.imread_color(path_A)\n",
        "\n",
        "                    nw = random.randint(0, img_B.shape[0] - self.crop_shape[0])\n",
        "                    nh = random.randint(0, img_B.shape[1] - self.crop_shape[1])\n",
        "\n",
        "                    crop_img_A = img_A[nw:nw + self.crop_shape[0], nh:nh + self.crop_shape[1], :]\n",
        "                    crop_img_B = img_B[nw:nw + self.crop_shape[0], nh:nh + self.crop_shape[1],:]\n",
        "                    \n",
        "                    # im = Image.fromarray(crop_img_A)\n",
        "                    # im.show()\n",
        "                    # im = Image.fromarray(crop_img_B)\n",
        "                    # im.show()\n",
        "\n",
        "                    if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
        "                        crop_img_A = np.flipud(crop_img_A)\n",
        "                        crop_img_B = np.flipud(crop_img_B)\n",
        "                    if np.random.randint(2, size=1)[0] == 1:\n",
        "                        crop_img_A = np.fliplr(crop_img_A)\n",
        "                        crop_img_B = np.fliplr(crop_img_B)\n",
        "                    if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
        "                        crop_img_A = np.transpose(crop_img_A, (1, 0, 2))\n",
        "                        crop_img_B = np.transpose(crop_img_B, (1, 0, 2))\n",
        "\n",
        "                    input_imgs[number, :, :, :] = np.concatenate([crop_img_A, crop_img_B], axis=-1)\n",
        "                    gt[number, :, :, :] = crop_img_B\n",
        "                    number += 1\n",
        "                yield input_imgs, gt\n",
        "\n",
        "def build_vgg():\n",
        "    vgg_model = VGG19(include_top=False, weights='imagenet')\n",
        "    vgg_model.trainable = False\n",
        "    return Model(inputs=vgg_model.input, outputs=vgg_model.get_layer('block3_conv4').output)\n",
        "\n",
        "def build_mbllen(input_shape):\n",
        "\n",
        "    def EM(input, kernal_size, channel):\n",
        "        conv_1 = Conv2D(channel, (3, 3), activation='relu', padding='same', data_format='channels_last')(input)\n",
        "        conv_2 = Conv2D(channel, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_1)\n",
        "        conv_3 = Conv2D(channel*2, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_2)\n",
        "        conv_4 = Conv2D(channel*4, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_3)\n",
        "        conv_5 = Conv2DTranspose(channel*2, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_4)\n",
        "        conv_6 = Conv2DTranspose(channel, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_5)\n",
        "        res = Conv2DTranspose(3, (kernal_size, kernal_size), activation='relu', padding='valid', data_format='channels_last')(conv_6)\n",
        "        return res\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    FEM = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(inputs)\n",
        "    EM_com = EM(FEM, 5, 8)\n",
        "\n",
        "    for j in range(4):                                                                                                                                      # MODIFICATION: WAS 3!\n",
        "        for i in range(0, 3):\n",
        "            FEM = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_last')(FEM)\n",
        "            EM1 = EM(FEM, 5, 8)\n",
        "            EM_com = Concatenate(axis=3)([EM_com, EM1])\n",
        "\n",
        "    outputs = Conv2D(3, (1, 1), activation='relu', padding='same', data_format='channels_last')(EM_com)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "def bright_mae(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_pred[:,:,:,:3] - y_true[:,:,:,:3]))\n",
        "\n",
        "def bright_mse(y_true, y_pred):\n",
        "    return K.mean((y_pred[:,:,:,:3] - y_true[:,:,:,:3])**2)\n",
        "\n",
        "def bright_AB(y_true, y_pred):\n",
        "            return K.abs(K.mean(y_true[:,:,:,:3])-K.mean(y_pred[:,:,:,:3]))\n",
        "\n",
        "def log10(x):\n",
        "    numerator = K.log(x)\n",
        "    denominator = K.log(K.constant(10, dtype=numerator.dtype))\n",
        "    return numerator / denominator\n",
        "\n",
        "def bright_psnr(y_true, y_pred):\n",
        "    mse = K.mean((K.abs(y_pred[:,:,:,:3] - y_true[:,:,:,:3])) ** 2)\n",
        "    max_num = 1.0\n",
        "    psnr = 10 * log10(max_num ** 2 / mse)\n",
        "    return psnr\n",
        "\n",
        "def _tf_fspecial_gauss(size, sigma):\n",
        "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "    \"\"\"\n",
        "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "\n",
        "    x_data = np.expand_dims(x_data, axis=-1)\n",
        "    x_data = np.expand_dims(x_data, axis=-1)\n",
        "\n",
        "    y_data = np.expand_dims(y_data, axis=-1)\n",
        "    y_data = np.expand_dims(y_data, axis=-1)\n",
        "\n",
        "    x = tf.constant(x_data, dtype=tf.float32)\n",
        "    y = tf.constant(y_data, dtype=tf.float32)\n",
        "\n",
        "    g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "    return g / tf.reduce_sum(g)\n",
        "\n",
        "def tf_ssim(img1, img2, cs_map=False, mean_metric=True, size=11, sigma=1.5):\n",
        "    window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "    K1 = 0.01\n",
        "    K2 = 0.03\n",
        "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "    C1 = (K1*L)**2\n",
        "    C2 = (K2*L)**2\n",
        "    mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
        "    mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1],padding='VALID')\n",
        "    mu1_sq = mu1*mu1\n",
        "    mu2_sq = mu2*mu2\n",
        "    mu1_mu2 = mu1*mu2\n",
        "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
        "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
        "    sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
        "    if cs_map:\n",
        "        value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                            (sigma1_sq + sigma2_sq + C2)),\n",
        "                        (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
        "    else:\n",
        "        value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                            (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if mean_metric:\n",
        "        value = tf.reduce_mean(value)\n",
        "    return value\n",
        "\n",
        "def tf_ms_ssim(img1, img2, mean_metric=True, level=5):\n",
        "    weight = tf.constant([0.0448, 0.2856, 0.3001, 0.2363, 0.1333], dtype=tf.float32)\n",
        "    mssim = []\n",
        "    mcs = []\n",
        "    for l in range(level):\n",
        "        ssim_map, cs_map = tf_ssim(img1, img2, cs_map=True, mean_metric=False)\n",
        "        mssim.append(tf.reduce_mean(ssim_map))\n",
        "        mcs.append(tf.reduce_mean(cs_map))\n",
        "        filtered_im1 = tf.nn.avg_pool(img1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "        filtered_im2 = tf.nn.avg_pool(img2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "        img1 = filtered_im1\n",
        "        img2 = filtered_im2\n",
        "\n",
        "    # list to tensor of dim D+1\n",
        "    mssim = tf.stack(mssim, axis=0)\n",
        "    mcs = tf.stack(mcs, axis=0)\n",
        "\n",
        "    value = (tf.reduce_prod(mcs[0:level-1]**weight[0:level-1])*\n",
        "                                    (mssim[level-1]**weight[level-1]))\n",
        "\n",
        "    if mean_metric:\n",
        "        value = tf.reduce_mean(value)\n",
        "    return value\n",
        "\n",
        "def bright_SSIM(y_true, y_pred):\n",
        "    SSIM_loss = tf_ssim(tf.expand_dims(y_pred[:,:,:,0], -1), tf.expand_dims(y_true[:,:,:,0], -1))+tf_ssim(tf.expand_dims(y_pred[:,:,:,1], -1), tf.expand_dims(y_true[:,:,:,1], -1)) + tf_ssim(tf.expand_dims(y_pred[:,:,:,2], -1), tf.expand_dims(y_true[:,:,:,2], -1))\n",
        "    return SSIM_loss/3\n",
        "\n",
        "def psnr_cau(y_true, y_pred):\n",
        "    mse = np.mean((np.abs(y_pred - y_true)) ** 2)\n",
        "    max_num = 1.0\n",
        "    psnr = 10 * np.log10(max_num ** 2 / mse)\n",
        "    return psnr\n",
        "\n",
        "def save_model(model, name, epoch, batch_i):\n",
        "    modelname = './Res_models/' + str(epoch) + '_' + str(batch_i) + name + '.h5'\n",
        "    model.save_weights(modelname)\n",
        "\n",
        "def imread_color(path):\n",
        "    img = cv.imread(path, cv.IMREAD_COLOR | cv.IMREAD_ANYDEPTH) / 255.\n",
        "    b, g, r = cv.split(img)\n",
        "    img_rgb = cv.merge([r, g, b])\n",
        "    return img_rgb\n",
        "    # return scipy.misc.imread(path, mode='RGB').astype(np.float) / 255.\n",
        "\n",
        "def imwrite(path, img):\n",
        "    r, g, b = cv.split(img*255)\n",
        "    img_rgb = cv.merge([b, g, r])\n",
        "    cv.imwrite(path, img_rgb)\n",
        "    # scipy.misc.toimage(img * 255, high=255, low=0, cmin=0, cmax=255).save(path)\n",
        "\n",
        "def range_scale(x):\n",
        "    return x * 2 - 1.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTUFYz-ytHg4",
        "colab_type": "code",
        "outputId": "72d51631-18c2-41bf-9192-10cc68fe351e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "def my_loss(y_true, y_pred):\n",
        "    MAE_loss = K.mean(K.abs(y_pred[:,:,:,:3] - y_true))\n",
        "    SSIM_loss = tf_ssim(tf.expand_dims(y_pred[:, :, :, 0], -1),tf.expand_dims(y_true[:, :, :, 0], -1)) + tf_ssim(\n",
        "        tf.expand_dims(y_pred[:, :, :, 1], -1), tf.expand_dims(y_true[:, :, :, 1], -1)) + tf_ssim(\n",
        "        tf.expand_dims(y_pred[:, :, :, 2], -1), tf.expand_dims(y_true[:, :, :, 2], -1))\n",
        "    VGG_loss = K.mean(K.abs(y_pred[:, :, :, 3:19] - y_pred[:, :, :, 19:35]))\n",
        "\n",
        "    percent = 0.4\n",
        "    index = int(256 * 256 * percent - 1)\n",
        "    gray1 = 0.39 * y_pred[:, :, :, 0] + 0.5 * y_pred[:, :, :, 1] + 0.11 * y_pred[:, :, :, 2]\n",
        "    gray = tf.reshape(gray1, [-1, 256 * 256])\n",
        "    gray_sort = tf.nn.top_k(-gray, 256 * 256)[0]\n",
        "    yu = gray_sort[:, index]\n",
        "    yu = tf.expand_dims(tf.expand_dims(yu, -1), -1)\n",
        "    mask = tf.dtypes.cast((gray1 <= yu), tf.float32)\n",
        "    mask1 = tf.expand_dims(mask, -1)\n",
        "    mask = tf.concat([mask1, mask1, mask1], -1)\n",
        "\n",
        "    low_fake_clean = tf.multiply(mask, y_pred[:, :, :, :3])\n",
        "    high_fake_clean = tf.multiply(1 - mask, y_pred[:, :, :, :3])\n",
        "    low_clean = tf.multiply(mask, y_true[:, :, :, :])\n",
        "    high_clean = tf.multiply(1 - mask, y_true[:, :, :, :])\n",
        "    Region_loss = K.mean(K.abs(low_fake_clean - low_clean) * 4 + K.abs(high_fake_clean - high_clean))\n",
        "\n",
        "    loss = MAE_loss + VGG_loss/3. + 3 - SSIM_loss + Region_loss\n",
        "    return loss\n",
        "\n",
        "if not os.path.isdir(ROOT_DIR + '/val_images2'):\n",
        "    os.makedirs(ROOT_DIR + '/val_images2')\n",
        "if not os.path.isdir(ROOT_DIR + '/logs'):\n",
        "    os.makedirs(ROOT_DIR + '/logs')\n",
        "if not os.path.isdir(ROOT_DIR + '/models'):\n",
        "    os.makedirs(ROOT_DIR + '/models')\n",
        "\n",
        "def f1(x):\n",
        "    return x[:, :, :, :3]\n",
        "\n",
        "def f2(x):\n",
        "    return x[:, :, :, 3:]\n",
        "\n",
        "def f3(x):\n",
        "    return tf.reshape(x,[-1, 256, 256, 16])\n",
        "\n",
        "img_channels = 3\n",
        "crop_shape = (img_rows, img_cols, img_channels)\n",
        "input_shape = (img_rows, img_cols, img_channels*2)\n",
        "dataset_name = 'lol'\n",
        "data_loader = Dataloader(dataset_name=dataset_name, crop_shape=(img_rows, img_cols))\n",
        "\n",
        "# ==================================================================\n",
        "# Build the network\n",
        "mbllen = build_mbllen(crop_shape)\n",
        "# mbllen.load_weights('./1_dark2_color_identity_param.h5')\n",
        "\n",
        "Input_MBLLEN = Input(shape=input_shape)\n",
        "img_A = Lambda(f1)(Input_MBLLEN)\n",
        "img_B = Lambda(f2)(Input_MBLLEN)\n",
        "\n",
        "# VGG19 feature, content loss\n",
        "vgg = build_vgg()\n",
        "vgg.trainable = False\n",
        "\n",
        "fake_B = mbllen(img_A)\n",
        "vgg_fake = Lambda(range_scale)(fake_B)\n",
        "fake_features = vgg(vgg_fake)\n",
        "fake_features = Lambda(f3)(fake_features)\n",
        "\n",
        "img_B_vgg = Lambda(range_scale)(img_B)\n",
        "imgb_features = vgg(img_B_vgg)\n",
        "imgb_features = Lambda(f3)(imgb_features)\n",
        "\n",
        "output_com = concatenate([fake_B, fake_features, imgb_features], axis=3)\n",
        "\n",
        "if LOAD_FROM_WEIGHTS == True:\n",
        "  start_learn_rate = RESUMED_LEARN_RATE\n",
        "else:\n",
        "  start_learn_rate = BASE_LEARN_RATE\n",
        "\n",
        "opt = Adam(lr=start_learn_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "combined = Model(inputs=Input_MBLLEN, outputs=output_com)\n",
        "combined.compile(loss=my_loss,\n",
        "                 metrics=[bright_mae, bright_mse, bright_psnr, bright_SSIM, bright_AB],\n",
        "                 optimizer=opt)\n",
        "\n",
        "# plot_model(mbllen, to_file='./model.png', show_shapes=True)\n",
        "combined.summary()\n",
        "\n",
        "# ==================================================================\n",
        "#\n",
        "def scheduler(epoch):\n",
        "    lr = K.eval(combined.optimizer.lr)\n",
        "    print(\"LR =\", lr)\n",
        "    lr = lr * 0.99\n",
        "    return lr\n",
        "\n",
        "# we will use this sequence for generating the random patch positions so that they are the same for each epoch\n",
        "# patch_positions = []\n",
        "num_epoch = 0\n",
        "class Show_History(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, val_loss=None, logs=None):\n",
        "        # save model\n",
        "        global num_epoch\n",
        "        global dataset_name\n",
        "        global img_rows\n",
        "        global img_cols\n",
        "        global mbllen\n",
        "        num_epoch += 1\n",
        "        modelname = ROOT_DIR + '/models/' + dataset_name + '/' + 'only_lol/' + str(num_epoch) + '_' + dataset_name + '_base.h5'           # MODIFICATION : added 'layers_2/'\n",
        "        mbllen.save_weights(modelname)\n",
        "\n",
        "        # test val data\n",
        "        path = glob(ROOT_DIR + '/dataset/eval15/high/*.png')\n",
        "        number = 0\n",
        "        psnr_ave = 0\n",
        "\n",
        "\n",
        "        for i in range(len(path)):\n",
        "            if i>15:\n",
        "                break\n",
        "\n",
        "            img_B_path = path[i]\n",
        "            img_B = imread_color(img_B_path)\n",
        "\n",
        "            # path_mid = os.path.split(img_B_path)\n",
        "            # path_A_1 = path_mid[0] + '_' + dataset_name\n",
        "            # path_A = os.path.join(path_A_1, path_mid[1])\n",
        "\n",
        "            path_split = os.path.split(img_B_path)\n",
        "            path_prefix = os.path.split(path_split[0])\n",
        "            path_A = path_prefix[0] + '/low/' + path_split[1]\n",
        "\n",
        "            img_A = imread_color(path_A)\n",
        "\n",
        "            nw = 100 #random.randint(0, img_A.shape[0] - img_rows)\n",
        "            nh = 150 #random.randint(0, img_A.shape[1] - img_cols)\n",
        "\n",
        "            crop_img_A = img_A[nw:nw + img_rows, nh:nh + img_cols, :]\n",
        "            crop_img_B = img_B[nw:nw + img_rows, nh:nh + img_cols, :]\n",
        "\n",
        "            crop_img_A = crop_img_A[np.newaxis, :]\n",
        "            crop_img_B = crop_img_B[np.newaxis, :]\n",
        "\n",
        "            fake_B = mbllen.predict(crop_img_A)\n",
        "            identy_B = mbllen.predict(crop_img_B)\n",
        "\n",
        "            out_img = np.concatenate([crop_img_A, fake_B, crop_img_B, identy_B], axis=2)\n",
        "            out_img = out_img[0, :, :, :]\n",
        "\n",
        "            fake_B = fake_B[0, :, :, :]\n",
        "            img_B = crop_img_B[0, :, :, :]\n",
        "\n",
        "            clean_psnr = psnr_cau(fake_B, img_B)\n",
        "            L_psnr = (\"%.4f\" % clean_psnr)\n",
        "\n",
        "            number += 1\n",
        "            psnr_ave += clean_psnr\n",
        "\n",
        "            im_name = path_split[1].split('.')[0]\n",
        "            filename = os.path.basename(path[i])\n",
        "            img_name = ROOT_DIR + VAL_DIR + '/' + str(num_epoch) + '_' + im_name + '_' + L_psnr + '_' + filename\n",
        "            imwrite(img_name, out_img)\n",
        "        psnr_ave /= number\n",
        "        print('------------------------------------------------')\n",
        "        print(\"[Epoch %d]  [PSNR_AVE :%f]\" % (num_epoch,  psnr_ave))\n",
        "        print('------------------------------------------------')\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        print(' - LR = ', K.eval(self.model.optimizer.lr))\n",
        "\n",
        "# ==================================================================\n",
        "#\n",
        "show_history = Show_History()\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "#tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False,\n",
        "#                                         embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
        "nanstop = keras.callbacks.TerminateOnNaN()\n",
        "reducelearate = keras.callbacks.ReduceLROnPlateau(monitor='lr', factor=0.5, patience=2, min_lr=1e-10)\n",
        "earlystop = keras.callbacks.EarlyStopping(monitor='lr', min_delta=3, patience=0, verbose=0, mode='min')\n",
        "\n",
        "if LOAD_FROM_WEIGHTS:\n",
        "  mbllen.load_weights(ROOT_DIR + '/models/em/' + MODEL_WEIGHTS_FILE)\n",
        "\n",
        "combined.fit_generator(\n",
        "        data_loader.load_data(BATCH_SIZE),\n",
        "        steps_per_epoch=STEPS_PER_EPOCH, # num_samples // batch_size\n",
        "        epochs=NUM_EPOCHS,\n",
        "        callbacks=[show_history, change_lr, nanstop, reducelearate])\n",
        "print('Done!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_38 (InputLayer)           [(None, 256, 256, 6) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_72 (Lambda)              (None, 256, 256, 3)  0           input_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_36 (Model)                (None, 256, 256, 3)  587727      lambda_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_73 (Lambda)              (None, 256, 256, 3)  0           input_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_74 (Lambda)              (None, 256, 256, 3)  0           model_36[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_76 (Lambda)              (None, 256, 256, 3)  0           lambda_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_37 (Model)                multiple             2325568     lambda_74[0][0]                  \n",
            "                                                                 lambda_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_75 (Lambda)              (None, 256, 256, 16) 0           model_37[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_77 (Lambda)              (None, 256, 256, 16) 0           model_37[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 256, 256, 35) 0           model_36[1][0]                   \n",
            "                                                                 lambda_75[0][0]                  \n",
            "                                                                 lambda_77[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,913,295\n",
            "Trainable params: 587,727\n",
            "Non-trainable params: 2,325,568\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 1 steps\n",
            "LR = 0.0\n",
            " - LR =  0.0\n",
            "------------------------------------------------\n",
            "[Epoch 1]  [PSNR_AVE :19.319271]\n",
            "------------------------------------------------\n",
            "1/1 [==============================] - 14s 14s/step - loss: 2.0089 - bright_mae: 0.1506 - bright_mse: 0.0347 - bright_psnr: 14.5908 - bright_SSIM: 0.7319 - bright_AB: 0.0881\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}